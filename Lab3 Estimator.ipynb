{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Azure ML compute clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/retkowsky/images/blob/master/AzureMLservicebanniere.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Azure Machine Learning Compute** is a **managed-compute infrastructure** that allows the user to easily create a single or multi-node compute. The compute is created within your workspace region as a resource that can be shared with other users in your workspace. The compute **scales up automatically when a job is submitted**, and can be put in an Azure Virtual Network. The compute executes in a containerized environment and packages your model dependencies in a **Docker container**.\n",
    "\n",
    "You can use Azure Machine Learning Compute to distribute the training process across a cluster of **CPU or GPU** compute nodes in the cloud. For more information on the VM sizes that include GPUs, see GPU-optimized virtual machine sizes.\n",
    "\n",
    "Azure Machine Learning Compute has default limits, such as the number of cores that can be allocated. For more information, see Manage and request quotas for Azure resources.\n",
    "\n",
    "You can create an Azure Machine Learning compute environment **on demand** when you schedule a run, or as a **persistent resource**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:<br>\n",
    "- https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target <br>\n",
    "- https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2021-04-12 08:35:37.669497\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"Date:\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using Azure ML 1.26.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"You are using Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "create workspace"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment\n",
    "\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'Lab3-AzureMLCompute'\n",
    "\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of experiments in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_experiments = Experiment.list(ws)\n",
    "#print(\"List of experiments :\")\n",
    "#for expname in list_experiments:\n",
    "#    print(expname.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Azure ML compute clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Documentation: https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute instances in your workspace Azure ML:\n",
      "- AzureDatabricks\n",
      "- instanceaks\n",
      "- my-aks-9\n",
      "- automl\n",
      "- computeinstancenb\n",
      "- cpu-cluster\n",
      "- computeinstanceds12\n",
      "- automlclus551001\n"
     ]
    }
   ],
   "source": [
    "print(\"Compute instances in your workspace Azure ML:\")\n",
    "cts = ws.compute_targets\n",
    "for ct in cts:\n",
    "    print('-', ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Available Azure ML Compute clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "#AmlCompute.supported_vmsizes(workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Directory\n",
    "\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train-on-amlcompute/train_aml.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './train-on-amlcompute'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy('train_aml.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's view the python code we want to submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft. All rights reserved.\n",
      "# Licensed under the MIT license.\n",
      "\n",
      "from sklearn.datasets import load_diabetes\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.model_selection import train_test_split\n",
      "from azureml.core.run import Run\n",
      "from sklearn.externals import joblib\n",
      "import os\n",
      "import numpy as np\n",
      "\n",
      "os.makedirs('./outputs', exist_ok=True)\n",
      "\n",
      "X, y = load_diabetes(return_X_y=True)\n",
      "\n",
      "run = Run.get_context()\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)\n",
      "data = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
      "        \"test\": {\"X\": X_test, \"y\": y_test}}\n",
      "\n",
      "# list of numbers from 0.0 to 1.0 with a 0.05 interval\n",
      "alphas = np.arange(0.0, 1.0, 0.05)\n",
      "\n",
      "for alpha in alphas:\n",
      "    # Use Ridge algorithm to create a regression model\n",
      "    reg = Ridge(alpha=alpha)\n",
      "    reg.fit(data[\"train\"][\"X\"], data[\"train\"][\"y\"])\n",
      "\n",
      "    preds = reg.predict(data[\"test\"][\"X\"])\n",
      "    mse = mean_squared_error(preds, data[\"test\"][\"y\"])\n",
      "    run.log('alpha', alpha)\n",
      "    run.log('mse', mse)\n",
      "\n",
      "    model_file_name = 'ridge_{0:.2f}.pkl'.format(alpha)\n",
      "    # save model in the outputs folder so it automatically get uploaded\n",
      "    with open(model_file_name, \"wb\") as file:\n",
      "        joblib.dump(value=reg, filename=os.path.join('./outputs/',\n",
      "                                                     model_file_name))\n",
      "\n",
      "    print('alpha is {0:.2f}, and mse is {1:0.2f}'.format(alpha, mse))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('./train-on-amlcompute/train_aml.py'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using scikit-learn = 0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('You are using scikit-learn =', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"myenv\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn==0.20.3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Documentation : https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute<br>\n",
    "> Pricing : https://azure.microsoft.com/en-us/pricing/details/machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to create a compute cluster based on a predefined VM instance. Then you can see the compute cluster from the Azure ML Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "sample-amlcompute-provision"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating....\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "CPU times: user 109 ms, sys: 7.54 ms, total: 117 ms\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Use an unique name\n",
    "cpu_cluster_name = 'clustertest'\n",
    "\n",
    "# Tags\n",
    "clusttags= {\"Type\": \"CPU\", \n",
    "            \"Priority\":\"Dedicated\",\n",
    "            \"Team\": \"DataScience\", \n",
    "            \"Country\": \"France\"}\n",
    "\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           vm_priority='dedicated',\n",
    "                                                           min_nodes = 0, # Min nodes of the cluster\n",
    "                                                           max_nodes = 4, # Max nodes of the cluster\n",
    "                                                           tags=clusttags, \n",
    "                                                           description=\"Compute Clusters Std D2V2\",\n",
    "                                                           idle_seconds_before_scaledown=18000) #Timeout for scaling down\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureDatabricks\n",
      "instanceaks\n",
      "my-aks-9\n",
      "automl\n",
      "computeinstancenb\n",
      "cpu-cluster\n",
      "computeinstanceds12\n",
      "automlclus551001\n",
      "clustertest\n"
     ]
    }
   ],
   "source": [
    "#List of available compute cluster in your workspace\n",
    "listcomputeservers = ws.compute_targets\n",
    "for list in listcomputeservers:\n",
    "    print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 0,\n",
       " 'targetNodeCount': 0,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 0,\n",
       "  'idleNodeCount': 0,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2021-04-12T08:35:47.680000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2021-04-12T08:35:44.921574+00:00',\n",
       " 'modifiedTime': '2021-04-12T08:36:00.340921+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 0,\n",
       "  'maxNodeCount': 4,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT18000S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cluster information\n",
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Python file we want to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 1538 Nov 16 13:54 train_aml.py\r\n"
     ]
    }
   ],
   "source": [
    "# This is the python code we want to execute\n",
    "!ls train_aml.py -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# 1. Python file\n",
    "src = ScriptRunConfig(source_directory=project_folder, script='train_aml.py')\n",
    "\n",
    "# 2. Set compute target to the one created in previous step\n",
    "src.run_config.target = cpu_cluster.name\n",
    "\n",
    "# 3. Set python environment\n",
    "src.run_config.environment = myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Some tags for the run\n",
    "runtags= {\"Type\": \"test\" , \n",
    "          \"Langage\" : \"Python\" , \n",
    "          \"Framework\" : \"Scikit-Learn\", \n",
    "          \"Team\" : \"DataScience\" , \n",
    "          \"Country\" : \"France\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Lab3-AzureMLCompute</td><td>Lab3-AzureMLCompute_1618216566_d24e1d92</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/Lab3-AzureMLCompute_1618216566_d24e1d92?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/AMLworkshop-rg/workspaces/AMLworkshop&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: Lab3-AzureMLCompute,\n",
       "Id: Lab3-AzureMLCompute_1618216566_d24e1d92,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's submit\n",
    "run = experiment.submit(config=src, tags=runtags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Interactive Notebook widget for viewing the run status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2c41f201514817bb83174952c97a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/Lab3-AzureMLCompute_1618216566_d24e1d92?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/AMLworkshop-rg/workspaces/AMLworkshop&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"Lab3-AzureMLCompute_1618216566_d24e1d92\", \"run_properties\": {\"run_id\": \"Lab3-AzureMLCompute_1618216566_d24e1d92\", \"created_utc\": \"2021-04-12T08:36:09.07755Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"eff3c2c9-03e5-47d1-8783-82a1c882dd35\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"Type\": \"test\", \"Langage\": \"Python\", \"Framework\": \"Scikit-Learn\", \"Team\": \"DataScience\", \"Country\": \"France\", \"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-04-12T08:49:17.993994Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=nfo%2B%2Fswk51FkV%2BoDSik3wVNSAxCKpyXj1XWQdFt%2Fu%2Fo%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/55_azureml-execution-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt?sv=2019-02-02&sr=b&sig=AzMdcuLCutM%2BErq1QC0cz9SdW3%2BRV0Pj4PHVMCYWrzw%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/65_job_prep-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt?sv=2019-02-02&sr=b&sig=g1vP7KXPOYpQ9S4Cr59MOUr84SPX5yIbeafuYaDwLV4%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=WIdFBBrB%2FV5%2FTq6oj98hkFf2QpLr%2B9BUVhsOeaZFfiQ%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"azureml-logs/75_job_post-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/75_job_post-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt?sv=2019-02-02&sr=b&sig=6JmJ3gCYEzfvhMBC6iioA0B4BroD9eTZS3GDmKHYO%2F0%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"azureml-logs/process_info.json\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=3nVrZUUJKYL5cxZDwqoUE6ZC2oHujsQwcvmUL3rMiKM%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"azureml-logs/process_status.json\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=k9Raa2LrkBexygzV1LprmD4U7w2Jp5LmEZYEV8iuYAs%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"logs/azureml/104_azureml.log\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/logs/azureml/104_azureml.log?sv=2019-02-02&sr=b&sig=%2F3kftH9UxbegoV57rp7jSBpPkaMbvjbyR1gVij1NbFs%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=AIgsnZImI8ilXcJXpj5GG2dieWD9e3f%2FnfoiKGecKDw%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=H6eNgECFicLlT0jn8oyPatldQ4uNpCH3Khjl%2BOXC1kE%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt\"], [\"logs/azureml/104_azureml.log\"]], \"run_duration\": \"0:13:08\", \"run_number\": \"54\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"alpha\", \"run_id\": \"Lab3-AzureMLCompute_1618216566_d24e1d92\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"series\": [{\"data\": [0.0, 0.05, 0.1, 0.15000000000000002, 0.2, 0.25, 0.30000000000000004, 0.35000000000000003, 0.4, 0.45, 0.5, 0.55, 0.6000000000000001, 0.65, 0.7000000000000001, 0.75, 0.8, 0.8500000000000001, 0.9, 0.9500000000000001]}]}, {\"name\": \"mse\", \"run_id\": \"Lab3-AzureMLCompute_1618216566_d24e1d92\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], \"series\": [{\"data\": [3424.3166882137343, 3408.9153122589296, 3372.649627810032, 3345.14964347419, 3325.294679467878, 3311.5562509289744, 3302.6736334017264, 3297.658733944204, 3295.74106435581, 3296.316884705676, 3298.9096058070622, 3303.140055527517, 3308.7042707723226, 3315.3568399622573, 3322.898314903962, 3331.1656169285875, 3340.024662032161, 3349.364644348603, 3359.093569748443, 3369.1347399130477]}]}], \"run_logs\": \"2021-04-12 08:48:53,785|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-04-12 08:48:53,787|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-04-12 08:48:53,794|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-04-12 08:48:53,794|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-04-12 08:48:54,263|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fc6efd59378> for run source azureml.scriptrun\\n2021-04-12 08:48:54,264|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-04-12 08:48:54,265|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-04-12 08:48:54,266|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-12 08:48:54,275|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-04-12 08:48:54,275|azureml.core.authentication|DEBUG|Time to expire 1813634.724125 seconds\\n2021-04-12 08:48:54,276|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-04-12 08:48:54,276|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-04-12 08:48:54,316|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,316|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,316|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,317|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,317|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,317|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,317|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,360|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-04-12 08:48:54,360|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-04-12 08:48:54,450|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-04-12 08:48:54,451|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'eff3c2c9-03e5-47d1-8783-82a1c882dd35', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-04-12 08:48:54,451|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-04-12 08:48:54,451|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-04-12 08:48:54,451|azureml.WorkerPool|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml.RunStatusContext|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml.MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-04-12 08:48:54,452|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/amlworkshop/azureml/lab3-azuremlcompute_1618216566_d24e1d92/mounts/workspaceblobstore/azureml/Lab3-AzureMLCompute_1618216566_d24e1d92\\n2021-04-12 08:48:54,452|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-04-12 08:48:54,453|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/amlworkshop/azureml/lab3-azuremlcompute_1618216566_d24e1d92/mounts/workspaceblobstore/azureml/Lab3-AzureMLCompute_1618216566_d24e1d92\\n2021-04-12 08:48:54,902|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-04-12 08:48:54,903|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-04-12 08:48:54,903|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-04-12 08:48:54,903|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,904|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,904|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,904|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,905|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,905|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,905|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-04-12 08:48:54,940|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-04-12 08:48:54,940|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-04-12 08:48:55,017|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-04-12 08:48:55,018|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'eff3c2c9-03e5-47d1-8783-82a1c882dd35', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-04-12 08:48:55,018|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-04-12 08:48:55,039|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-04-12 08:48:55,040|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-12 08:48:55,040|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-04-12 08:48:55,694|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-04-12 08:48:55,694|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/amlworkshop/azureml/lab3-azuremlcompute_1618216566_d24e1d92/mounts/workspaceblobstore/azureml/Lab3-AzureMLCompute_1618216566_d24e1d92\\n2021-04-12 08:48:55,694|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/amlworkshop/azureml/lab3-azuremlcompute_1618216566_d24e1d92/mounts/workspaceblobstore/azureml/Lab3-AzureMLCompute_1618216566_d24e1d92 to /mnt/batch/tasks/shared/LS_root/jobs/amlworkshop/azureml/lab3-azuremlcompute_1618216566_d24e1d92/mounts/workspaceblobstore/azureml/Lab3-AzureMLCompute_1618216566_d24e1d92\\n2021-04-12 08:48:55,694|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/amlworkshop/azureml/lab3-azuremlcompute_1618216566_d24e1d92/mounts/workspaceblobstore/azureml/Lab3-AzureMLCompute_1618216566_d24e1d92\\n2021-04-12 08:48:55,694|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-04-12 08:48:55,694|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-04-12 08:48:55,695|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,695|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-04-12 08:48:55,695|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-12 08:48:55,695|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-04-12 08:48:55,695|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,695|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,696|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-04-12 08:48:55,697|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-04-12 08:48:55,697|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,697|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,697|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-04-12 08:48:55,697|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-04-12 08:48:55,779|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,780|azureml.MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-04-12 08:48:55,780|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-04-12 08:48:55,781|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-04-12 08:48:55,863|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-04-12 08:48:55,863|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-04-12 08:48:55,863|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,863|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,863|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-04-12 08:48:55,864|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,865|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,865|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-04-12 08:48:55,865|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-04-12 08:48:55,941|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-04-12 08:48:55,941|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,942|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-04-12 08:48:55,942|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-04-12 08:48:55,942|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-04-12 08:48:55,943|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,943|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,943|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-04-12 08:48:55,943|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-04-12 08:48:55,943|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:55,943|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-04-12 08:48:55,943|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-04-12 08:48:55,944|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 40.\\n2021-04-12 08:48:55,944|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-04-12 08:48:55,944|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-04-12 08:48:55,944|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-04-12 08:48:55,945|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 40 values.\\n2021-04-12 08:48:55,945|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-04-12 08:48:55,945|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-04-12 08:48:55,945|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-04-12 08:48:55,945|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-04-12 08:48:55,946|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-04-12 08:48:55,946|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-04-12 08:48:55,946|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-04-12 08:48:55,959|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-04-12 08:48:55,959|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-04-12 08:48:55,959|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-04-12 08:48:55,960|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-04-12 08:48:55,960|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-04-12 08:48:55,960|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-04-12 08:48:55,960|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-04-12 08:48:55,961|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-04-12 08:48:55,961|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-04-12 08:48:56,253|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-04-12 08:48:56,461|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-04-12 08:48:56,462|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-04-12 08:48:56,462|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-04-12 08:48:56,462|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.0002675056457519531 seconds.\\nWaiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.25037288665771484 seconds.\\n\\n2021-04-12 08:48:56,462|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:56,462|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-04-12 08:48:56,463|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-04-12 08:48:56,463|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-04-12 08:48:56,539|azureml._SubmittedRun#Lab3-AzureMLCompute_1618216566_d24e1d92.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-04-12 08:49:01,543|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-04-12 08:49:01,623|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-04-12 08:49:01,623|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-04-12 08:49:01,624|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-04-12 08:49:01,624|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Checking run status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the run status using the widget, the Azure ML studio or using this python code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status: \n",
    "preparing -> running -> finalizing -> completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status = Completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Status =\", run.get_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'Lab3-AzureMLCompute_1618216566_d24e1d92',\n",
       " 'target': 'clustertest',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-04-12T08:46:08.749027Z',\n",
       " 'endTimeUtc': '2021-04-12T08:49:17.993994Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'eff3c2c9-03e5-47d1-8783-82a1c882dd35',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train_aml.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'clustertest',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'myenv',\n",
       "   'version': 'Autosave_2021-04-12T08:36:08Z_334fe002',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.26.0']},\n",
       "      'scikit-learn==0.20.3'],\n",
       "     'name': 'azureml_b25cb7c017801e19c4f7d1ee92ea188a'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=nfo%2B%2Fswk51FkV%2BoDSik3wVNSAxCKpyXj1XWQdFt%2Fu%2Fo%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/55_azureml-execution-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt?sv=2019-02-02&sr=b&sig=AzMdcuLCutM%2BErq1QC0cz9SdW3%2BRV0Pj4PHVMCYWrzw%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/65_job_prep-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt?sv=2019-02-02&sr=b&sig=g1vP7KXPOYpQ9S4Cr59MOUr84SPX5yIbeafuYaDwLV4%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=WIdFBBrB%2FV5%2FTq6oj98hkFf2QpLr%2B9BUVhsOeaZFfiQ%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/75_job_post-tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d.txt?sv=2019-02-02&sr=b&sig=6JmJ3gCYEzfvhMBC6iioA0B4BroD9eTZS3GDmKHYO%2F0%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=3nVrZUUJKYL5cxZDwqoUE6ZC2oHujsQwcvmUL3rMiKM%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=k9Raa2LrkBexygzV1LprmD4U7w2Jp5LmEZYEV8iuYAs%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'logs/azureml/104_azureml.log': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/logs/azureml/104_azureml.log?sv=2019-02-02&sr=b&sig=%2F3kftH9UxbegoV57rp7jSBpPkaMbvjbyR1gVij1NbFs%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=AIgsnZImI8ilXcJXpj5GG2dieWD9e3f%2FnfoiKGecKDw%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://amlworkshop1458610383.blob.core.windows.net/azureml/ExperimentRun/dcid.Lab3-AzureMLCompute_1618216566_d24e1d92/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=H6eNgECFicLlT0jn8oyPatldQ4uNpCH3Khjl%2BOXC1kE%3D&st=2021-04-12T08%3A39%3A13Z&se=2021-04-12T16%3A49%3A13Z&sp=r'},\n",
       " 'submittedBy': 'Serge Retkowsky'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.0,\n",
       "  0.05,\n",
       "  0.1,\n",
       "  0.15000000000000002,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.30000000000000004,\n",
       "  0.35000000000000003,\n",
       "  0.4,\n",
       "  0.45,\n",
       "  0.5,\n",
       "  0.55,\n",
       "  0.6000000000000001,\n",
       "  0.65,\n",
       "  0.7000000000000001,\n",
       "  0.75,\n",
       "  0.8,\n",
       "  0.8500000000000001,\n",
       "  0.9,\n",
       "  0.9500000000000001],\n",
       " 'mse': [3424.3166882137343,\n",
       "  3408.9153122589296,\n",
       "  3372.649627810032,\n",
       "  3345.14964347419,\n",
       "  3325.294679467878,\n",
       "  3311.5562509289744,\n",
       "  3302.6736334017264,\n",
       "  3297.658733944204,\n",
       "  3295.74106435581,\n",
       "  3296.316884705676,\n",
       "  3298.9096058070622,\n",
       "  3303.140055527517,\n",
       "  3308.7042707723226,\n",
       "  3315.3568399622573,\n",
       "  3322.898314903962,\n",
       "  3331.1656169285875,\n",
       "  3340.024662032161,\n",
       "  3349.364644348603,\n",
       "  3359.093569748443,\n",
       "  3369.1347399130477]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': [3424.3166882137343,\n",
       "  3408.9153122589296,\n",
       "  3372.649627810032,\n",
       "  3345.14964347419,\n",
       "  3325.294679467878,\n",
       "  3311.5562509289744,\n",
       "  3302.6736334017264,\n",
       "  3297.658733944204,\n",
       "  3295.74106435581,\n",
       "  3296.316884705676,\n",
       "  3298.9096058070622,\n",
       "  3303.140055527517,\n",
       "  3308.7042707723226,\n",
       "  3315.3568399622573,\n",
       "  3322.898314903962,\n",
       "  3331.1656169285875,\n",
       "  3340.024662032161,\n",
       "  3349.364644348603,\n",
       "  3359.093569748443,\n",
       "  3369.1347399130477]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics('mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's the results in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>Lab3-AzureMLCompute</td><td>AMLworkshop</td><td><a href=\"https://ml.azure.com/experiments/id/b5a33b0e-6c62-42ed-9907-01261a1e6b96?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/AMLworkshop-rg/workspaces/AMLworkshop&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: Lab3-AzureMLCompute,\n",
       "Workspace: AMLworkshop)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your compute cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 1,\n",
       " 'targetNodeCount': 1,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 1,\n",
       "  'idleNodeCount': 0,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2021-04-12T08:45:43.619000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2021-04-12T08:35:44.921574+00:00',\n",
       " 'modifiedTime': '2021-04-12T08:36:00.340921+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 0,\n",
       "  'maxNodeCount': 4,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT18000S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Status:\")\n",
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'nodeId': 'tvmps_ed4c230b615ed40c6e01f3ed848baacc30345fa763043c5b5b42595b31549dbb_d',\n",
       "  'port': 50001,\n",
       "  'publicIpAddress': '51.105.255.98',\n",
       "  'privateIpAddress': '10.0.0.5',\n",
       "  'nodeState': 'idle'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Nodes:\")\n",
    "cpu_cluster.list_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'westeurope'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster.cluster_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 4, 12, 8, 35, 44, 921574, tzinfo=tzlocal())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster.created_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STANDARD_D2_V2'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster.vm_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can change some settings of the compute clusters using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currentNodeCount': 1,\n",
       " 'targetNodeCount': 1,\n",
       " 'nodeStateCounts': {'preparingNodeCount': 0,\n",
       "  'runningNodeCount': 1,\n",
       "  'idleNodeCount': 0,\n",
       "  'unusableNodeCount': 0,\n",
       "  'leavingNodeCount': 0,\n",
       "  'preemptedNodeCount': 0},\n",
       " 'allocationState': 'Steady',\n",
       " 'allocationStateTransitionTime': '2021-04-12T08:45:43.619000+00:00',\n",
       " 'errors': None,\n",
       " 'creationTime': '2021-04-12T08:35:44.921574+00:00',\n",
       " 'modifiedTime': '2021-04-12T08:36:00.340921+00:00',\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'provisioningStateTransitionTime': None,\n",
       " 'scaleSettings': {'minNodeCount': 0,\n",
       "  'maxNodeCount': 4,\n",
       "  'nodeIdleTimeBeforeScaleDown': 'PT18000S'},\n",
       " 'vmPriority': 'Dedicated',\n",
       " 'vmSize': 'STANDARD_D2_V2'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_cluster.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu_cluster.update(min_nodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu_cluster.update(max_nodes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpu_cluster.update(idle_seconds_before_scaledown=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster.update(min_nodes=2, max_nodes=4, idle_seconds_before_scaledown=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deleting'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster.provisioning_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can now open the Lab5 notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/retkowsky/images/blob/master/Powered-by-MS-Azure-logo-v2.png?raw=true\" height=\"300\" width=\"300\">"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "nigup"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "Train on Azure Machine Learning Compute",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Submit a run on Azure Machine Learning Compute."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
